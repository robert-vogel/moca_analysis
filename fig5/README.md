# Scripts and process used

**Note** This is not a state-of-the art diagnostic tool, or the optimal 
training of each computer vision model.
Instead we are showing the usefulness of combining predictions
from arbitraily complex data and models.  This model cannot
be used to classify skin features in general or a 
clinical setting, only to be
used in this simple demonstration.


## Downloading data

The data consists of thumbnails, smaller than full image,
of skin features.  These skin features are classified as
benign or malignant, i.e. a binary classification problem.
We download 3 collections from the ISIC-archive
https://api.isic-archive.com/images/

* MSK-1, collection id = 289
    - 1,678 thumbnail images where diagnoses are either
        confirmed by histopathology and / or "clinical follow-up".
* MSK-2, collection id = 290
    - 4,880 biopsy confirmed thumbnail images
* MSK-4, collection id = 287
    - 2,050 thumbnail images with diagnoses confirmed by histopathology

These data were downloaded using the `download_collections.py` script,
and ran from the command line by:

```bash
python download_collections.py --dir imgs_train 289
python download_collections.py --dir imgs_train 290
python download_collections.py --dir imgs_validate 287
```

Next I checked that the thumbnail images are:

* License "CC-0", public domain
* benign_malignant field value is either benign or malignant
* image jpeg file exists

The `isic_id` of thumbnail images that satisfy these criteria
are written to the file specified by the `-o` flag.  Otherwise,
print the `isic_id` and reason first reason of failure to the
standard out.

```bash
for fname in $(ls imgs_train/*.json); do
    python make_data_table.py -o data/train_set.tsv \
        --img_json $fname >> "data/exclude_train_images.tsv"
done

for fname in $(ls imgs_validate/*.json); do
    python make_data_table.py -o data/validate_set.csv \
        --img_json $fname >> "data/exclude_validate_images.tsv"
done
```

Lastly, I check that images are unique using command
line tools

```bash
ls -1 imgs_train/*.jpeg | wc -l
ls -1 imgs_train/*.jpeg | sort | uniq | wc -l
```

A subset of images in each data set didn't have the requisite
metadata and were consequently omitted from the analysis.  In total
we have

* training: 6524 thumbnail images
    - benign: 4508 thumbnail images
    - malignant: 2016 thumbnail images
* validate: 1903 thumbnail images
    - benign: 1164 thumbnail images
    - malignant: 739 thumbnail images


### Format image directory for transfer learning with TensorFlow

The simplest way to assign class labels to images is to organize
images in directories per class.  The script `format_img_dir_by_class.py`
does this, and removes images that are excluded because they
didn't meet are criteria for inclusion.  This script was run at the
command line as

```bash
python format_img_dir_by_class.py --img_list data/train_set.tsv \
    --img_exclude_list data/excluded_train_images.tsv \
    --img_dir imgs_train
```

For the validation set, I simply remove image files that do 
not be our criteria for inclusion.


## Transfer learning training

We followed 
[TensorFlow's](https://www.tensorflow.org/tutorials/images/transfer_learning)
tutorial on transfer learning.  Again, our purpose it not
to train the optimal base classifiers, but to show that
the aggregation of distinct classifiers increases performance.

Elements of `transfer_learning.py` code contains
code snippets, with and without modification,
from the transfer learning tutorial created
and shared by Google under the Apache 2.0 License.

`transfer_learning.py` was run from the command line by

```bash
python transfer_learning.py \
    --train_dir imgs_train \
    --validate_dir imgs_validate \
    --out_dir data \
    --validate_set_metadata data/validate_set.tsv \
    --seed 6283475
```

where `imgs_train` consisted of two directories, 'benign'
and 'malignant' for which the respective images were located.
TensorFlow provides tools for the automatic class assignments
from such a directory structure.
The validation set images were located in `imgs_train`.  I
do not include the thumbnail image files, as these can be readily
downloaded from the ISIC-archive.  The result of this program
is the `data/prediction.csv` file contain the sample
score of each image produced by each TensorFlow model.


Training was done on each model for a single epoch.
Training and validation set predictions takes
approximately one hour on a laptop.


### `MobileNet`

[TensorFlow API documentation](https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet/MobileNet)


*BibTeX Reference*

Citation generated by `arxiv.org`

```
@misc{howard2017mobilenets,
      title={MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications}, 
      author={Andrew G. Howard and Menglong Zhu and Bo Chen and Dmitry Kalenichenko and Weijun Wang and Tobias Weyand and Marco Andreetto and Hartwig Adam},
      year={2017},
      eprint={1704.04861},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```


### `InceptionV3`

[TensorFlow API documentation](https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/InceptionV3)

*BibTeX Reference*

Citation generated by `arxiv.org`

```
@misc{szegedy2015rethinking,
      title={Rethinking the Inception Architecture for Computer Vision}, 
      author={Christian Szegedy and Vincent Vanhoucke and Sergey Ioffe and Jonathon Shlens and Zbigniew Wojna},
      year={2015},
      eprint={1512.00567},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

### `resnet50`

[TensorFlow API documentation](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50)

*BibTeX Reference*

Citation generated by `arxiv.org`

```
@misc{he2015deep,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

### `NASNetMobile`


[TensorFlow API documentation](https://www.tensorflow.org/api_docs/python/tf/keras/applications/nasnet/NASNetMobile)

*BibTeX Reference*

Citation generated by `arxiv.org`

```
@misc{zoph2018learning,
      title={Learning Transferable Architectures for Scalable Image Recognition}, 
      author={Barret Zoph and Vijay Vasudevan and Jonathon Shlens and Quoc V. Le},
      year={2018},
      eprint={1707.07012},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```




### `VGG19`


[TensorFlow API documentation](https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg19/VGG19) 


*BibTeX Reference*

Citation generated by `arxiv.org`

```
@misc{simonyan2015deep,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```


### `Xception`

[TensorFlow API documentation](https://www.tensorflow.org/api_docs/python/tf/keras/applications/xception/Xception)


*BibTeX Reference*

Citation generated by `arxiv.org`


```
@misc{chollet2017xception,
      title={Xception: Deep Learning with Depthwise Separable Convolutions}, 
      author={Fran√ßois Chollet},
      year={2017},
      eprint={1610.02357},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```



## Moca tests

